# üîç FAISS-Based Semantic Search with Llama and SentenceTransformers

This project demonstrates **semantic search** using:
- **Llama (via Llama.cpp)** for language model processing
- **SentenceTransformers (all-MiniLM-L6-v2)** for sentence embeddings
- **FAISS (Facebook AI Similarity Search)** for fast similarity search

## üöÄ Features
‚úÖ Loads a **Llama-based language model** (`mistral-7b-instruct-v0.1.Q4_0.gguf`)  
‚úÖ Uses **SentenceTransformers** to generate embeddings for text  
‚úÖ Stores and searches embeddings efficiently with **FAISS**  
‚úÖ Finds the most relevant document snippets based on input queries  

---

## üì¶ Installation

### 1Ô∏è‚É£ **Clone the Repository**
```sh
git clone https://github.com/your-repo-name.git
cd your-repo-name
```
### 2Ô∏è‚É£ Set Up a Virtual Environment
```sh
python -m venv venv
source venv/bin/activate  # On Windows use: venv\Scripts\activate
```
### 3Ô∏è‚É£ Install Dependencies
```sh
pip install -r requirements.txt
```
## üìå Usage

### 1Ô∏è‚É£ Run the Jupyter Notebook

jupyter notebook main.ipynb

### 2Ô∏è‚É£ What the Notebook Does

 - Loads a Llama model from a local .gguf file.
 - fines a list of technical documentation snippets.
 - Converts the text into embeddings using SentenceTransformers.
 - Indexes the embeddings with FAISS.
 - Allows querying for similar documents using FAISS.

## ‚ö° Example Code Snippet
```python
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

# Load the embedding model
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")

# Sample documentation
docs = [
    "Install Python: Download and install Python from python.org.",
    "Set up a virtual environment: Run 'python -m venv env' and activate it.",
    "Deploy a web app: Use Heroku, AWS, or DigitalOcean."
]

# Convert docs to embeddings
doc_embeddings = embedding_model.encode(docs)

# Create a FAISS index
index = faiss.IndexFlatL2(doc_embeddings.shape[1])
index.add(np.array(doc_embeddings))  # Add embeddings

# Query for similar docs
query_embedding = embedding_model.encode(["How to deploy an application?"])
distances, indices = index.search(query_embedding, k=2)
print("Most similar document indices:", indices)
```
## üõ† Technologies Used
 - Python 3.x
 - FAISS (Facebook AI Similarity Search)
 - SentenceTransformers (Hugging Face)
 - Llama.cpp (Meta AI)
 - Jupyter Notebook

## üìú License
This project is licensed under the **MIT License** ‚Äì see the [LICENSE](LICENSE) file for details.

## üí° Future Enhancements
 - Implement real-time API using FastAPI for search queries.
 - Integrate web-based UI for document lookup.
 - Add larger language models for better search relevance.

## ü§ù Contributing

Contributions are welcome! Feel free to open issues or submit pull requests.

## ‚ú® Acknowledgments
 - Meta AI for Llama.cpp
 - Hugging Face for SentenceTransformers
 - Facebook AI for FAISS

---